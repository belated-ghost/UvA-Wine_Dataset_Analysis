{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTpWDh3V24sH"
      },
      "source": [
        "**Oksana Harapyn (14711133)\n",
        "Danylo Redka (14795051)\n",
        "Sergey Romadin (14988585)\n",
        "**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hOqUCcPP2xrt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY46jqux5O47"
      },
      "source": [
        "1.1 Classification on Wine Datase\n",
        "\n",
        "On the one hand it can be advategeous as multi-class classification aligns better with the discrete nature of wine quality, potentially yielding more interpretable results. Nevertheless, same approach disregards nuances in quality differences, leading to potential loss of information compared to regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkcIJ3MYFxzt"
      },
      "source": [
        "**2 Portugese Banking Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CCZZ96Gl38Oz"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test_label = pd.read_csv(\"test_label.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oPIa5J8TGtSy"
      },
      "outputs": [],
      "source": [
        "train_noID_Dummies = pd.get_dummies(train.drop([\"ID\"], axis=1))\n",
        "test_noID_Dummies = pd.get_dummies(test.drop([\"ID\"], axis=1))\n",
        "test_label_noID_Dummies = pd.get_dummies(test_label.drop([\"ID\"], axis=1))\n",
        "X_train_unscaled = train_noID_Dummies.drop([\"y_no\", \"y_yes\"], axis=1)\n",
        "X_test_unscaled = test_noID_Dummies\n",
        "y_train = train_noID_Dummies[\"y_yes\"]\n",
        "y_test = test_label_noID_Dummies[\"y_yes\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckh-ITSJHPsS",
        "outputId": "7f2a59b5-bd7f-446b-ced6-d0cd0769abf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal value for the regularization parameter C using Standard Scaler and LinSVC is: 0.03162277660168379\n",
            "Optimal value for the regularization parameter C using MinMax Scaler and LinSVC is: 1.0\n",
            "The score of the LinearSVC classifier using Standard Scaler is: 0.7762759263574924\n",
            "The score of the LinearSVC classifier using MinMax Scaler is: 0.7762759263574924\n",
            "Optimal value for the regularization parameter C using unscaled data and LinSVC is: 1.0\n",
            "The score of the LinearSVC classifier (unscaled data) is: 0.7760428804474482\n"
          ]
        }
      ],
      "source": [
        "pipe_StScaler_LinSVC = make_pipeline(StandardScaler(), LinearSVC())\n",
        "pipe_MMScaler_LinSVC = make_pipeline(MinMaxScaler(), LinearSVC())\n",
        "\n",
        "param_grid_LinSVC = {\"linearsvc__C\": np.logspace(-3, 3, 5)}\n",
        "grid_StScaler_LinSVC = GridSearchCV(pipe_StScaler_LinSVC, param_grid_LinSVC, cv=10)\n",
        "grid_MMScaler_LinSVC = GridSearchCV(pipe_MMScaler_LinSVC, param_grid_LinSVC, cv=10)\n",
        "\n",
        "\n",
        "\n",
        "grid_StScaler_LinSVC.fit(X_train_unscaled, y_train)\n",
        "grid_MMScaler_LinSVC.fit(X_train_unscaled, y_train)\n",
        "\n",
        "LinSVC_StScaler_C_best = grid_StScaler_LinSVC.best_params_[\"linearsvc__C\"]\n",
        "LinSVC_MMScaler_C_best = grid_MMScaler_LinSVC.best_params_[\"linearsvc__C\"]\n",
        "print(\"Optimal value for the regularization parameter C using Standard Scaler and LinSVC is: \" + str(LinSVC_StScaler_C_best))\n",
        "print(\"Optimal value for the regularization parameter C using MinMax Scaler and LinSVC is: \" + str(LinSVC_MMScaler_C_best))\n",
        "\n",
        "\n",
        "\n",
        "LinSVC_StScaler_score = grid_StScaler_LinSVC.score(X_test_unscaled, y_test)\n",
        "LinSVC_MMScaler_score = grid_MMScaler_LinSVC.score(X_test_unscaled, y_test)\n",
        "print(\"The score of the LinearSVC classifier using Standard Scaler is: \" + str(LinSVC_StScaler_score))\n",
        "print(\"The score of the LinearSVC classifier using MinMax Scaler is: \" + str(LinSVC_MMScaler_score))\n",
        "\n",
        "pipe_unscaled_LinSVC = make_pipeline(LinearSVC())\n",
        "\n",
        "grid_LinSVC = GridSearchCV(pipe_unscaled_LinSVC, param_grid_LinSVC, cv=10)\n",
        "grid_LinSVC.fit(X_train_unscaled, y_train)\n",
        "\n",
        "LinSVC_unscaled_C_best = grid_LinSVC.best_params_[\"linearsvc__C\"]\n",
        "print(\"Optimal value for the regularization parameter C using unscaled data and LinSVC is: \" + str(LinSVC_unscaled_C_best))\n",
        "\n",
        "LinSVC_score = grid_LinSVC.score(X_test_unscaled, y_test)\n",
        "print(\"The score of the LinearSVC classifier (unscaled data) is: \" + str(LinSVC_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAaITglGLCj-"
      },
      "source": [
        "**LinearSVC**\n",
        "\n",
        "The LinearSVC model performs similarly across scaled and unscaled data, with a slight improvement in score when using the Standard Scaler 0.7763 compared to unscaled data 0.7760. The optimal regularization parameter CC varies slightly based on scaling but doesnâ€™t notably affect performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs8Xk7LSLH0r",
        "outputId": "a1f6f0a9-325e-4817-ee48-0226ccdb3f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal value for the regularization parameter C using Standard Scaler and LogReg is: 0.01\n",
            "Optimal value for the regularization parameter C using MinMax Scaler and LogReg is: 100.0\n",
            "The score of the LogisticRegression classifier using Standard Scaler is: 0.7795385690981124\n",
            "The score of the LogisticRegression classifier using MinMax Scaler is: 0.7800046609182009\n",
            "Optimal value for the regularization parameter C using unscaled data and LogReg is: 1000.0\n",
            "The score of the LogisticRegression classifier (unscaled data) is: 0.7795385690981124\n"
          ]
        }
      ],
      "source": [
        "pipe_StScaler_LogReg = make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear'))\n",
        "pipe_MMScaler_LogReg = make_pipeline(MinMaxScaler(), LogisticRegression(solver='liblinear'))\n",
        "\n",
        "param_grid_LogReg = {\"logisticregression__C\": np.logspace(-2, 3, 6)}\n",
        "\n",
        "grid_StScaler_LogReg = GridSearchCV(pipe_StScaler_LogReg, param_grid_LogReg, cv=10, n_jobs=-1)\n",
        "grid_MMScaler_LogReg = GridSearchCV(pipe_MMScaler_LogReg, param_grid_LogReg, cv=10, n_jobs=-1)\n",
        "\n",
        "grid_StScaler_LogReg.fit(X_train_unscaled, y_train)\n",
        "grid_MMScaler_LogReg.fit(X_train_unscaled, y_train)\n",
        "\n",
        "LogReg_StScaler_C_best = grid_StScaler_LogReg.best_params_[\"logisticregression__C\"]\n",
        "LogReg_MMScaler_C_best = grid_MMScaler_LogReg.best_params_[\"logisticregression__C\"]\n",
        "print(\"Optimal value for the regularization parameter C using Standard Scaler and LogReg is: \" + str(LogReg_StScaler_C_best))\n",
        "print(\"Optimal value for the regularization parameter C using MinMax Scaler and LogReg is: \" + str(LogReg_MMScaler_C_best))\n",
        "\n",
        "LogReg_StScaler_score = grid_StScaler_LogReg.score(X_test_unscaled, y_test)\n",
        "LogReg_MMScaler_score = grid_MMScaler_LogReg.score(X_test_unscaled, y_test)\n",
        "print(\"The score of the LogisticRegression classifier using Standard Scaler is: \" + str(LogReg_StScaler_score))\n",
        "print(\"The score of the LogisticRegression classifier using MinMax Scaler is: \" + str(LogReg_MMScaler_score))\n",
        "\n",
        "pipe_unscaled_LogReg = make_pipeline(LogisticRegression(solver='liblinear'))\n",
        "grid_LogReg = GridSearchCV(pipe_unscaled_LogReg, param_grid_LogReg, cv=10, n_jobs=-1)\n",
        "grid_LogReg.fit(X_train_unscaled, y_train)\n",
        "\n",
        "LogReg_unscaled_C_best = grid_LogReg.best_params_[\"logisticregression__C\"]\n",
        "print(\"Optimal value for the regularization parameter C using unscaled data and LogReg is: \" + str(LogReg_unscaled_C_best))\n",
        "\n",
        "LogReg_score = grid_LogReg.score(X_test_unscaled, y_test)\n",
        "print(\"The score of the LogisticRegression classifier (unscaled data) is: \" + str(LogReg_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDFyFw0sNOMt"
      },
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "The Logistic Regression model performs similarly across scaled and unscaled data, with a slight improvement in score when using the MinMax Scaler 0.7800 compared to Standard Scaler 0.7795 and unscaled data 0.7795. The optimal regularization parameter C varies significantly depending on the scaling method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-T8wWxhNTY2",
        "outputId": "50a74e59-e37a-4bba-c6c3-0e5470385fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal value for n_neighbors using Standard Scaler and KNN is: 11\n",
            "Optimal value for n_neighbors using MinMax Scaler and KNN is: 11\n",
            "The score of the KNeighborsClassifier classifier using Standard Scaler is: 0.7718480540666511\n",
            "The score of the KNeighborsClassifier classifier using MinMax Scaler is: 0.7653227685854114\n",
            "Optimal value for n_neighbors using unscaled data and KNN is: 11\n",
            "The score of the KNeighborsClassifier classifier (unscaled data) is: 0.7152178979258914\n"
          ]
        }
      ],
      "source": [
        "pipe_StScaler_KNN = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
        "pipe_MMScaler_KNN = make_pipeline(MinMaxScaler(), KNeighborsClassifier())\n",
        "\n",
        "param_grid_KNN = {\"kneighborsclassifier__n_neighbors\": [3, 5, 7, 9, 11]}\n",
        "\n",
        "grid_StScaler_KNN = GridSearchCV(pipe_StScaler_KNN, param_grid_KNN, cv=10)\n",
        "grid_MMScaler_KNN = GridSearchCV(pipe_MMScaler_KNN, param_grid_KNN, cv=10)\n",
        "\n",
        "grid_StScaler_KNN.fit(X_train_unscaled, y_train)\n",
        "grid_MMScaler_KNN.fit(X_train_unscaled, y_train)\n",
        "\n",
        "KNN_StScaler_n_neighbors_best = grid_StScaler_KNN.best_params_[\"kneighborsclassifier__n_neighbors\"]\n",
        "KNN_MMScaler_n_neighbors_best = grid_MMScaler_KNN.best_params_[\"kneighborsclassifier__n_neighbors\"]\n",
        "print(\"Optimal value for n_neighbors using Standard Scaler and KNN is: \" + str(KNN_StScaler_n_neighbors_best))\n",
        "print(\"Optimal value for n_neighbors using MinMax Scaler and KNN is: \" + str(KNN_MMScaler_n_neighbors_best))\n",
        "\n",
        "KNN_StScaler_score = grid_StScaler_KNN.score(X_test_unscaled, y_test)\n",
        "KNN_MMScaler_score = grid_MMScaler_KNN.score(X_test_unscaled, y_test)\n",
        "print(\"The score of the KNeighborsClassifier classifier using Standard Scaler is: \" + str(KNN_StScaler_score))\n",
        "print(\"The score of the KNeighborsClassifier classifier using MinMax Scaler is: \" + str(KNN_MMScaler_score))\n",
        "\n",
        "pipe_unscaled_KNN = make_pipeline(KNeighborsClassifier())\n",
        "grid_KNN = GridSearchCV(pipe_unscaled_KNN, param_grid_KNN, cv=10)\n",
        "grid_KNN.fit(X_train_unscaled, y_train)\n",
        "\n",
        "KNN_unscaled_n_neighbors_best = grid_KNN.best_params_[\"kneighborsclassifier__n_neighbors\"]\n",
        "print(\"Optimal value for n_neighbors using unscaled data and KNN is: \" + str(KNN_unscaled_n_neighbors_best))\n",
        "\n",
        "KNN_score = grid_KNN.score(X_test_unscaled, y_test)\n",
        "print(\"The score of the KNeighborsClassifier classifier (unscaled data) is: \" + str(KNN_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIs5GH7tP8iO"
      },
      "source": [
        "**KNeighborsClassifier**\n",
        "\n",
        "The KNeighborsClassifier model performs best with # of neighbous is 11 for both Standard and MinMax scaling. The Standard Scaler yields the highest score 0.7718, followed by MinMax Scaler 0.7653, and unscaled data 0.715. Scaling improves performance significantly compared to unscaled data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5w3qQ5jQBT3",
        "outputId": "7706ffbe-36e0-4c0f-e9d9-9bf22af014d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Accuracy:  0.6790957818690282\n",
            "Classification Report for Decision Tree:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.75      0.76      2969\n",
            "        True       0.48      0.52      0.50      1322\n",
            "\n",
            "    accuracy                           0.68      4291\n",
            "   macro avg       0.63      0.64      0.63      4291\n",
            "weighted avg       0.69      0.68      0.68      4291\n",
            "\n",
            "Confusion Matrix for Decision Tree:\n",
            " [[2225  744]\n",
            " [ 633  689]]\n",
            "Best Hyperparameters for Decision Tree:  {'max_depth': 10, 'max_features': None}\n",
            "Best Decision Tree Model Accuracy:  0.7675990675990676\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "\n",
        "dt_model.fit(X_train_unscaled, y_train)\n",
        "dt_accuracy = dt_model.score(X_test_unscaled, y_test)\n",
        "\n",
        "print(\"Decision Tree Accuracy: \", dt_accuracy)\n",
        "\n",
        "y_pred_dt = dt_model.predict(X_test_unscaled)\n",
        "\n",
        "print(\"Classification Report for Decision Tree:\\n\", classification_report(y_test, y_pred_dt))\n",
        "print(\"Confusion Matrix for Decision Tree:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
        "\n",
        "param_grid_dt = {'max_depth': [3, 5, 10, None],'max_features': ['sqrt', 'log2', None]}\n",
        "grid_dt = GridSearchCV(dt_model, param_grid_dt, cv=10)\n",
        "\n",
        "grid_dt.fit(X_train_unscaled, y_train)\n",
        "print(\"Best Hyperparameters for Decision Tree: \", grid_dt.best_params_)\n",
        "print(\"Best Decision Tree Model Accuracy: \", grid_dt.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K19QD_rPSUpg"
      },
      "source": [
        "**Decision Tree**\n",
        "\n",
        "The Decision Tree model shows a relatively high accuracy of 0.68, but its performance on the minority class \"True\" is weaker with a recall of 0.52. The grid search suggests that a maximum depth of 10 and no restriction on features yield the best performance, improving the model's accuracy to 0.77. This indicates that while the model is prone to underperforming on imbalanced data, tuning can help optimize results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
